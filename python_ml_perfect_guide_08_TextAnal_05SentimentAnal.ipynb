{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1q4kxSao655QUcbuphE5sEuttL6UdDLIO",
      "authorship_tag": "ABX9TyMXlpa3frjqVs/WicFRKJfJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johyunkang/python-ml-guide/blob/main/python_ml_perfect_guide_08_TextAnal_05SentimentAnal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 05 감성분석"
      ],
      "metadata": {
        "id": "GQVWdWfH6fza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 감성 분석은 머신러닝 관점에서 지도학습, 비지도학습으로 나눌 수 있음\n",
        "    - 지도학습은 학습 데이터와 타깃 레이블 값을 기반으로 감성 분석 학습을 수행한 뒤 이를 기반으로 다른 데이터의 감성 분석을 예측하는 방법으로 일반적인 텍스트 기반의 분류와 거의 동일함\n",
        "    - 비지도학습은 'Lexicon'이라는 일종의 감성 어휘 사전을 이용. Lexicon은 감성 분석을 위한 용어와 문맥에 대한 다양한 정보를 가지고 있으며, 이를 이용해 문서의 긍정적, 부정적 감성 여부를 판단함"
      ],
      "metadata": {
        "id": "nrV2js5S7Et4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 지도학습 기반 감성 분석 실습 - IMDB 영화평"
      ],
      "metadata": {
        "id": "nBRz-niK75sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "review_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/text-anal/labeledTrainData.tsv.zip',\n",
        "                        header=0, sep=\"\\t\", quoting=3)\n",
        "review_df.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PMTVgRpm9Wz9",
        "outputId": "2b118c52-c16a-44ba-bd63-64d02518c16e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe3f6681-126a-4c16-a9a2-7dc43476f3ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe3f6681-126a-4c16-a9a2-7dc43476f3ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fe3f6681-126a-4c16-a9a2-7dc43476f3ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fe3f6681-126a-4c16-a9a2-7dc43476f3ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 의미\n",
        "    - id : 각 데이터 id\n",
        "    - sentiment : 영화평의 Sentiment 결과 값(Target Label). 1은 긍정적 평가, 0은 부정적 평가\n",
        "    - review : 영화평의 텍스트"
      ],
      "metadata": {
        "id": "vZGS4GQ_-T0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(review_df['review'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIa59ruQ-jvC",
        "outputId": "2649c6f7-f81d-4673-f77f-633cbac5e885"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re # 정규표현식 모듈\n",
        "\n",
        "# <br> html 태그는 replace 함수로 공백 변환\n",
        "review_df['review'] = review_df['review'].str.replace('<br />', ' ')\n",
        "\n",
        "# 파이썬의 정규 표현식 모듈인 re를 이용해 영어 문자열이 아닌 문자는 모두 공백으로 변환\n",
        "review_df['review'] = review_df['review'].apply(lambda x : re.sub(\"[^a-zA-Z]\", \" \", x))"
      ],
      "metadata": {
        "id": "5j70GSRZ_SLi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결정 값 클래스인 sentiment 컬럼 별도 추출해 결정 값 데이터 세트 생성"
      ],
      "metadata": {
        "id": "FqnsYf4D_0Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class_df = review_df['sentiment']\n",
        "feature_df = review_df.drop(['id', 'sentiment'], axis=1, inplace=False)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(feature_df, class_df, test_size=0.3, random_state=156)\n",
        "x_train.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_VcsVWu_-JN",
        "outputId": "a448081f-c9d3-4ce7-81ca-466f23fc7ac6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17500, 1), (7500, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pipeline 을 이용해 Count 벡터화 적용해 예측 성능을 측정"
      ],
      "metadata": {
        "id": "ziyW02HcE1qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# 스톱 워드는 english, filtering, ngram은 (1, 2)로 설정해 CountVectorization 수행\n",
        "# 선형회귀의 C는 10으로 설정\n",
        "pipeline = Pipeline([\n",
        "    ('cnt_vect', CountVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
        "    ('lr_clf', LogisticRegression(C=10))\n",
        "])\n",
        "\n",
        "# pipeline 객체를 이용해 fit(), predict()로 학습/예측 수행\n",
        "# predict_proba()는 roc_auc 때문에 수행\n",
        "pipeline.fit(x_train['review'], y_train)\n",
        "pred = pipeline.predict(x_test['review'])\n",
        "pred_probs = pipeline.predict_proba(x_test['review'])[:, 1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test, pred),\n",
        "                                                 roc_auc_score(y_test, pred)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEmaqBq4E9Bs",
        "outputId": "6b8c8816-8a5b-4836-9d64-f66e0c4826a6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도는 0.8860, ROC-AUC는 0.8859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> LogisticRegression의 C는 하이퍼 파라미터. 높은 C를 설정할 수록, 낮은 강도의 제약조건이 설정되고, 낮은 C를 설정할 수록, 높은 강도의 제약조건이 설정됨"
      ],
      "metadata": {
        "id": "ub1WrZAwAu3L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이번에는 TF-IDF 벡터화를 이용해 성능 측정"
      ],
      "metadata": {
        "id": "rbrdhsu9Ih4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stop words는 english , filtering, ngram은 (1, 2)로 설정해 TF-IDF 벡터화 수행\n",
        "# LogisticRegression 의 하이퍼 파라미터 C는 10으로 설정\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
        "    ('lr_clf', LogisticRegression(C=10))\n",
        "])\n",
        "\n",
        "pipeline.fit(x_train['review'], y_train)\n",
        "pred = pipeline.predict(x_test['review'])\n",
        "pred_proba = pipeline.predict_proba(x_test['review'])[:, 1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test, pred),\n",
        "                                                 roc_auc_score(y_test, pred)))"
      ],
      "metadata": {
        "id": "YjQAGulBIlGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Count 벡터화의 예측 정화도는 0.8860, ROC-AUC는 0.8859\n",
        "- TF-IDF 벡터화의 예측 정확도는 0.8936, ROC-AUC는 0.8934\n",
        "- TF-IDF 기반의 피처 벡터화의 예측 성능이 조금 더 나아졌음"
      ],
      "metadata": {
        "id": "Oen7tQCxJgDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 비지도학습 기반 감성 분석 소개"
      ],
      "metadata": {
        "id": "yXnwnvuJJwA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 비지도 감성 분석은 Lexicon을 기반으로 하는 것입니다.\n",
        "- Lexicon은 일반적으로 어휘집을 의미하지만 여기서는 감성만을 분석하기 위해 지원하는 감성 어휘 사전임.\n",
        "- 감성사전은 긍정(Positive) 또는 부정(Negative) 수치를 가지고 있으며 이를 감성지수(Polarity score)라고 함\n",
        "- 감성 지수는 단어의 위치나 주변 단어, 문맥, POS(Part of Speech) 등을 참고해 결정됨"
      ],
      "metadata": {
        "id": "thYCg8oRJ4Ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SentiWordNet을 이용한 감성 분석"
      ],
      "metadata": {
        "id": "iOSEA4s1Lhu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "TFSNrWHHLpR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 'present' 단어에 대한 Synset을 추출해 보겠음\n",
        "- WordNet의 synsets()는 파라미터로 지정된 단어에 대해 WordNet에 등재된 모든 Synset 객체를 반환함"
      ],
      "metadata": {
        "id": "LzKGWK20L3Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "term = 'present'\n",
        "\n",
        "# 'present'라는 단어로 wordnet의 synsets 생성\n",
        "synsets = wn.synsets(term)\n",
        "print('synsets() 반환 type:', type(synsets))\n",
        "print('synsets() 반환 값 개수:', len(synsets))\n",
        "print('synsets() 반환 값:', synsets)"
      ],
      "metadata": {
        "id": "ApRa2p-5MF8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위의 Synset 객체를 가지는 리스트는 총 18개임\n",
        "- Synset('present.n.01')와 같이 Synset 객체의 파라미터 'present.n.01'은 POS 태그를 나타냄\n",
        "- 'present.n.01'에서 present는 의미, n은 명사 품사, 01은 present가 명사로서 가지는 의미가 여러 가지 있어서 이를 구분하는 인덱스"
      ],
      "metadata": {
        "id": "PmSEugnmMpDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for synset in synsets :\n",
        "    print('#### Synset name:', synset.name(), '####')\n",
        "    print('POS:', synset.lexname())\n",
        "    print('Definition:', synset.definition())\n",
        "    print('Lemmas:', synset.lemma_names())\n",
        "    print('\\n\\n')"
      ],
      "metadata": {
        "id": "ZUOfmeFbNDEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- WordNet은 어떤 어휘와 다른 어휘 간의 관계를 유사도로 나타냄\n",
        "- synset 객체는 단어 간의 유사도를 나타내기 위해 path_similarity() 메서드 제공\n",
        "- path_similarity()를 이용해 'tree', 'lion', 'tiger', 'cat', 'dog' 단어의 상호 유사도를 살펴보겠음"
      ],
      "metadata": {
        "id": "bs29-vtrN81A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# synset 객체를 단어별로 생성\n",
        "tree = wn.synset('tree.n.01')\n",
        "lion = wn.synset('lion.n.01')\n",
        "tiger = wn.synset('tiger.n.02')\n",
        "cat = wn.synset('cat.n.01')\n",
        "dog = wn.synset('dog.n.01')\n",
        "\n",
        "entities = [tree, lion, tiger, cat, dog]\n",
        "similarities = []\n",
        "entity_names = [entity.name().split('.')[0] for entity in entities]\n",
        "\n",
        "# 단어별 synset을 반복하면서 다른 단어의 synset과 유사도를 측정\n",
        "for entity in entities :\n",
        "    similarity = [round(entity.path_similarity(compared_entity), 2) for compared_entity in entities]\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# 개별 단어별 synset과 다른 단어의 synset과의 유사도를 DF 형태로 저장\n",
        "similarity_df = pd.DataFrame(similarities, columns=entity_names, index=entity_names)\n",
        "similarity_df"
      ],
      "metadata": {
        "id": "fiMZLnxeORcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- lion 과 tree 의 유사도가 0.07로 가장 적음\n",
        "- lion 과 tiger 의 유사도는 0.33으로 가장 큼\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pSjjH2E-PtPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import nltk\n",
        " from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        " senti_synsets = list(swn.senti_synsets('slow'))\n",
        " print('senti_synsets() 변환 type:', type(senti_synsets))\n",
        " print('senti_synsets() 변환 값 개수:', len(senti_synsets))\n",
        " print('senti_synsets() 변환 값:', senti_synsets)"
      ],
      "metadata": {
        "id": "napLqOf9QCJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SentiSynset 객체는 단어의 감성을 나타내는 감성지수와 객관성(감성과 반대)을 나타내는 객관성 지수를 가지고 있음\n",
        "- 어떤 단어가 전혀 감성적이지 않으면 객관성 지수는 1, 감성 지수는 0이 됨"
      ],
      "metadata": {
        "id": "BZxSNyxIQqT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "father = swn.senti_synset('father.n.01')\n",
        "\n",
        "print('father 긍정 감성지수 :', father.pos_score())\n",
        "print('father 부정 감성지수 :', father.neg_score())\n",
        "print('father 객관성 지수 :', father.obj_score())\n",
        "print(\"\\n\")\n",
        "\n",
        "fabulous = swn.senti_synset('fabulous.a.01')\n",
        "print('fabulous 긍정 감성지수 :', fabulous.pos_score())\n",
        "print('fabulous 부정 감성지수 :', fabulous.neg_score())\n",
        "print('fabulous 객관성 지수 :', fabulous.obj_score())"
      ],
      "metadata": {
        "id": "NNWoubPPQ5kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SentiWordNet을 이용한 영화 감상평 감성 분석\n",
        "\n",
        "감성 분석을 수행하는 순서는 다음과 같음\n",
        "1. 문서(Document)를 문장(Sentence) 단위로 분해\n",
        "2. 다시 문장을 단어(Word) 단위로 토큰화하고 품사 태깅\n",
        "3. 품사 태깅된 단어 기반으로 synset 객체와 senti_synset 객체를 생성\n",
        "4. Senti_synset 에서 긍정 감성 / 부정 감성 지수를 구하고 이를 모두 합산해 특정 임계치 값 이상일 때 긍정 감성으로, 그렇지 않으면 부정으로 결정"
      ],
      "metadata": {
        "id": "czlJdkjrRmmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 품사를 태깅하는 내부 함수 생성"
      ],
      "metadata": {
        "id": "wmz4WuluSCjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# 간단한 NLTK PennTreebank Tag를 기반으로 WordNet 기반의 품사 Tag로 변환\n",
        "def penn_to_wn(tag) :\n",
        "    if tag.startwith('J') :\n",
        "        return wn.ADJ\n",
        "    elif tag.startwith('N') :\n",
        "        return wn.NOUN\n",
        "    elif tag.startwith('R') :\n",
        "        return wn.ADV\n",
        "    elif tag.startwith('V') :\n",
        "        return wn.VERB\n",
        "    "
      ],
      "metadata": {
        "id": "rW8NRc2mSGPP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문서를 문장 > 단어 토큰 > 품사 태깅 후 Polarity Score를 합산하는 함수 생성"
      ],
      "metadata": {
        "id": "gbF_XMqXSsWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
        "\n",
        "def swn_polarity(text) :\n",
        "    # 감성 지수 초기화\n",
        "    sentiment = 0.0\n",
        "    tokens_count = 0\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    raw_sentences = sent_tokenize(text)\n",
        "\n",
        "    # 분해된 문장별로 단어 토큰 > 품사 태깅 후 SentiSynset 생성 > 감성 지수 합산\n",
        "    for raw_sentence in raw_sentences :\n",
        "        # NLTK 기반의 품사 태깅 문장 추출\n",
        "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
        "        for word, tag in tagged_sentence:\n",
        "\n",
        "            # WordNet 기반 품사 태깅과 어근 추출\n",
        "            wn_tag = penn_to_wn(tag)\n",
        "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV) :\n",
        "                continue\n",
        "            \n",
        "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
        "            if not lemma :\n",
        "                continue\n",
        "            \n",
        "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성\n",
        "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
        "            if not synsets :\n",
        "                continue\n",
        "\n",
        "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
        "            # 모든 단어에 대해 긍정 감성 지수는 +로, 부정 감성 지수는 -로 합산해 감성 지수 계산\n",
        "            synset = synsets[0]\n",
        "            swn_synset = swn.senti_synset(synset.name())\n",
        "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n",
        "            tokens_count += 1\n",
        "        if not tokens_count :\n",
        "            return 0\n",
        "\n",
        "        # 총 score 가 0 이상일 경우 긍정(Positive) 1, 아님 부정(Negative) 0 반환\n",
        "        if sentiment >= 0 :\n",
        "            return 1\n",
        "\n",
        "        return 0"
      ],
      "metadata": {
        "id": "EIV9ZzM_S3GY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['preds'] = train_df['review'].apply(lambda x : swn_polarity(x))\n",
        "y_target = train_df['sentiment'].values\n",
        "preds = train_df['preds'].values"
      ],
      "metadata": {
        "id": "G9T0i2YmUmjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "p. 509"
      ],
      "metadata": {
        "id": "lsGkJoVqU-KT"
      }
    }
  ]
}